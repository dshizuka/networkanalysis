---
title: "9. Comparing against the Null Hypothesis: Permutations and Randomizations"
author: "Dai Shizuka"
date: "7/12/2018"
output: 
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: false
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(fig.width=4, fig.height=3.5, message=F) 
set.seed(2)
```

Packages you'll need:
```{r message=F}
library(asnipe)
library(igraph)
```

-----

Thus far, we have learned how to measure empirical networks in a variety of ways. However, we are often not satisfied with simply constructing and measuring networks. What we really want to know is: does our empirical network show some patterns that deviates from a random process? 

This brings us to hypothesis testing--that is, we want to compare the properties of our networks against some baseline, i.e., a null hypothesis/model. That is, we can ask the question: is our network non-random? 

The problem with this simplistic question, however, is that no real network is ever random. There are a multitude of factors that make networks deviate from an idealized Erdös-Renyí random graph (see [7. Random Graphs)(07_randomnets.html)) 

Because most networks are complex and relational data do not conform to the requirement of non-independence of data, we often use randomizations/permutations to generate null models against which we can compare the empirical data. Here, we focus narrowly on some classic forms of null model hypothesis testing using randomizations. In the context of animal social networks, there have been a couple of good review and tutorial of this method (Croft et al. 2011; Farine & Whitehead 2015). We will provide a quick overview here.

##8.1 Node-label Permutations

Node-label permutations involve shuffling the node type or node values (e.g., sex, size, etc.) randomly across all nodes in a network, while keeping the edges the same. This ensures that the inherent structural pattern of the network remains the same, but the node values are randomized. This type of randomization scheme may be appropriate when you are interested in understanding how node attributes affect connectivity of nodes, e.g.:

(a) testing correlations between node attribute and network position 
(b) using as null model for assortativity


###8.1.1 Example with flock simulation

Let's re-create the flock simulation from [section 8](08_simulations.html). In this simulation, we set up 50 individuals with variation in a trait as well as variation in gregariousness (probability of joining a given flock). Based on these parameters, we simulate observations of 100 flocks, then create a network. 

```{r fig.height=6}
set.seed(2)
n=50 #populatoin
trait=sort(rnorm(n,mean=20, sd=5), decreasing = T) #trait
p=sort(runif(n, min=0.01, max=0.1)) #gregariousness
f=100 #number of flock observations

#Now set up and construct simulated flock observations
ibg=matrix(0,nrow=n, ncol=f)

for(i in 1:n){
  for (j in 1:f){
  ibg[i,j]=sample(c(1,0), 1, prob=c(p[i], 1-p[i]))
  }
}

#calculate association index (simple ratio index) from this individual-by-group matrix.
adj=get_network(t(ibg), data_format="GBI", association_index="SRI")

#create and plot network, with vertex size proportional to trait value
g=graph_from_adjacency_matrix(adj, "undirected", weighted=T)
plot(g,vertex.size=trait/2, vertex.label="", edge.width=E(g)$weight*5)
```

We showed in this simulation that degree centrality is correlated to the trait:
```{r}
plot(trait, degree(g), pch=19)
cor.test(trait, degree(g))
```

Now, let's test whether this pattern is statistically significant. That is, what is the probability that one would get this level of correlation between trait and degree by chance?

First, let's store the correlation coefficient from our observed (simulated) network:

```{r}
obs.cor=cor(trait, degree(g))
obs.cor
```

Now, what we want to do is figure out what would be the correlation coefficient between trait and node degree if the trait value was randomized across individuals. This is what is called node label permutation. 

What we need to do is randomize the trait value across individuals. 

Here is one way:
```{r}
V(g)$trait=trait

V(g)$trait.random=sample(V(g)$trait, length(V(g)$trait), replace=F)

plot(V(g)$trait.random, degree(g))
cor(V(g)$trait.random, degree(g))
```

Now, we will conduct this randomization a large number of times (say 1000 times) and measure the correlation coefficient each time. This will generate a null distribution of the correlation coefficient.

```{r}
times=1000
cor.random=vector(length=times)
for(i in 1:times){
  V(g)$trait.random=sample(V(g)$trait, length(V(g)$trait), replace=F)
  cor.random[i]=cor(V(g)$trait.random, degree(g))
}
hist(cor.random, xlim=c(-1,1))
abline(v=obs.cor, lty=2, col="red")
```

```{r}
p.value=length(which(cor.random<=obs.cor))/(times+1)
p.value
```
