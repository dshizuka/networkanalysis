<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Dai Shizuka" />


<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Network Analysis Tutorials</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="tutorials.html">Tutorials</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore"><ol start="9" style="list-style-type: decimal">
<li>Testing against the Null Hypothesis: Permutations and Randomizations</li>
</ol></h1>
<h4 class="author"><em>Dai Shizuka</em></h4>
<h4 class="date"><em>7/12/2018</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#node-label-permutations">8.1 Node-label Permutations</a><ul>
<li><a href="#example-with">8.1.1 Example with…</a></li>
</ul></li>
<li><a href="#edge-permutations">8.2 Edge Permutations</a><ul>
<li><a href="#unconstrained-edge-permutations">8.2.1 Unconstrained edge permutations</a></li>
<li><a href="#edge-rewiring-while-keeping-the-degree-distribution-constant">8.2.2. Edge rewiring while keeping the degree distribution constant</a></li>
<li><a href="#group-membership-permutation">8.3 Group membership permutation</a></li>
<li><a href="#example-with-flock-simulation">8.1.1 Example with flock simulation</a></li>
</ul></li>
</ul>
</div>

<p>Packages you’ll need:</p>
<pre class="r"><code>library(asnipe)
library(igraph)
library(assortnet)</code></pre>
<hr />
<p>Thus far, we have learned how to measure empirical networks in a variety of ways. However, we are often not satisfied with simply constructing and measuring networks. What we really want to know is: does our empirical network show some patterns that deviates from a random process?</p>
<p>This brings us to hypothesis testing–that is, we want to compare the properties of our networks against some baseline, i.e., a null hypothesis/model. That is, we can ask the question: is our network non-random?</p>
<p>The problem with this simplistic question, however, is that no real network is ever random. There are a multitude of factors that make networks deviate from an idealized Erdös-Renyí random graph (see [7. Random Graphs)(07_randomnets.html))</p>
<p>Because most networks are complex and relational data do not conform to the requirement of non-independence of data, we often use randomizations/permutations to generate null models against which we can compare the empirical data. Here, we focus narrowly on some classic forms of null model hypothesis testing using randomizations. In the context of animal social networks, there have been a couple of good review and tutorial of this method (Croft et al. 2011; Farine &amp; Whitehead 2015). We will provide a quick overview here.</p>
<div id="node-label-permutations" class="section level2">
<h2>8.1 Node-label Permutations</h2>
<p>Node-label permutations involve shuffling the node type or node values (e.g., sex, size, etc.) randomly across all nodes in a network, while keeping the edges the same. This ensures that the inherent structural pattern of the network remains the same, but the node values are randomized. This type of randomization scheme may be appropriate when you are interested in understanding how node attributes affect connectivity of nodes, e.g.:</p>
<ol style="list-style-type: lower-alpha">
<li>testing correlations between node attribute and network position</li>
<li>using as null model for assortativity</li>
</ol>
<div id="example-with" class="section level3">
<h3>8.1.1 Example with…</h3>
</div>
</div>
<div id="edge-permutations" class="section level2">
<h2>8.2 Edge Permutations</h2>
<p>May be appropriate when:</p>
<ul>
<li>Not necessarily testing for the roles of particular node types</li>
<li>Testing whether structure of network is non-random… but what is random?</li>
<li>Must be careful about exactly how we permute edges–do we want to preserve any aspect of the connectivity of nodes?</li>
</ul>
<div id="unconstrained-edge-permutations" class="section level3">
<h3>8.2.1 Unconstrained edge permutations</h3>
<p>One straight-forward way to randomize edges in a network is to generate ‘random graphs’ in which there are the same number of nodes and edges as the empirical network, but the edges are now distributed randomly. One can create such networks by generating a ‘Erdös-Renyí random graph’ or by ‘rewiring’ the network randomly.</p>
</div>
<div id="edge-rewiring-while-keeping-the-degree-distribution-constant" class="section level3">
<h3>8.2.2. Edge rewiring while keeping the degree distribution constant</h3>
<p>Alternatively, we may want to ask whether the degree distribution itself may affect the clustering coefficient of the network. That is, if the distribution of node degrees is non-random, that alone may cause the clustering coefficient to be larger than expected by Erdös-Renyí random graph. We can implement this with the <code>rewire()</code> function as well, with a different method. I’ll briefly explain how this edge rewiring method works. This method is sometimes called the “switching” algorithm because it works by identifying two edges that connect different pairs of edges and then switches the ends of these nodes (illustrated below). Milo et al. (2003) found that this method works well and produces a randomized graph after implementing this switching step <span class="math inline">\(m\)</span> number of times, where <span class="math inline">\(m\)</span> is the number of edges in the network.</p>
<div class="figure">
<img src="assets/images/rewire.png" alt="Figure illustrating the rewiring algorithm to preserve the degree distribution. The numbers in the nodes represent their degrees. In one step of the switching algorithm, we identify a pair of connected nodes that themselves are not connected to each other (represented in different colors), and we simply swap the ends of the two edges. You can see that this does not change the degree of the nodes." />
<p class="caption"><em>Figure illustrating the rewiring algorithm to preserve the degree distribution. The numbers in the nodes represent their degrees. In one step of the switching algorithm, we identify a pair of connected nodes that themselves are not connected to each other (represented in different colors), and we simply swap the ends of the two edges. You can see that this does not change the degree of the nodes.</em></p>
</div>
</div>
<div id="group-membership-permutation" class="section level3">
<h3>8.3 Group membership permutation</h3>
<p>The edge randomization with constant degree sequence as described above preserves much more of the network structure than a completely random graph. However, these edge randomization methods are both using association indices that are non-random based on the group membership of individuals. An alternative way to conduct a randomization is to permute the group membership data (i.e., the original group-by-individual matrix) such that we randomize which group (e.g., flock) that each individual is in. Now I will explain how the group membership swapping works. This method is sometimes called the “swap algorithm”, or “flipping procedure”. It is actually the same algorithm that community ecologists use to generate a null model for species co-occurrences (see Manly 1995; Gotelli 2000; Ulrich &amp; Gotelli 2007). It has been adapted for generating a null model for social associations in animals by Bejder et al. (1998) and advocated for use in social network studies (Whitehead et al. 2005).</p>
<p>Step 1: Identify a 2x2 sub-matrix within the bipartite matrix that looks like: <span class="math inline">\(\begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \\ \end{bmatrix}\)</span></p>
<p>Step 2: Swap the row/columns so that the 2x2 matrix looks like: <span class="math inline">\(\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \\ \end{bmatrix}\)</span></p>
<div class="figure">
<img src="assets/images/swap.png" alt="Figure: One iteration of the sequential swap process. You can see that the row and column totals remain the same after each swap." />
<p class="caption"><em>Figure: One iteration of the sequential swap process. You can see that the row and column totals remain the same after each swap.</em></p>
</div>
<p>There are generally two ways to generate a P-value using the group membership swapping algorithm. First, one could repeat the swaps until the test statistic of interest (modularity in this case) stabilizes to a range of values corresponding to a randomized matrix, and then repeat this procedure a large number of times, say 1,000 times, to calculate a distribution of the test statistic under the null model (let’s call it the ‘global test’). Alternatively, one can run a large number of swaps from a single initial matrix, calculating a test statistic after each ‘swap’ of the matrix, and compare this distribution against the empirical test statistic (‘serial test’). Manly (1995) discusses why the serial method is a valid method for testing whether the empirical matrix is non-random as long as we conduct a very large number of swaps. I will not get into the logic behind this: I highly recommend reading the Manly (1995) and references therein. The ‘serial test’ method is much more computationally efficient than the ‘global test’.</p>
<p>Remove… too complicated</p>
</div>
<div id="example-with-flock-simulation" class="section level3">
<h3>8.1.1 Example with flock simulation</h3>
<p>Let’s re-create the flock simulation from <a href="08_simulations.html">section 8</a>. In this simulation, we set up 50 individuals with variation in a trait as well as variation in gregariousness (probability of joining a given flock). Based on these parameters, we simulate observations of 100 flocks, then create a network.</p>
<pre class="r"><code>set.seed(2)
n=50 #populatoin
trait=sort(rnorm(n,mean=20, sd=5), decreasing = T) #trait
p=sort(runif(n, min=0.01, max=0.1)) #gregariousness
f=100 #number of flock observations

#Now set up and construct simulated flock observations
ibg=matrix(0,nrow=n, ncol=f)

for(i in 1:n){
  for (j in 1:f){
  ibg[i,j]=sample(c(1,0), 1, prob=c(p[i], 1-p[i]))
  }
}

#calculate association index (simple ratio index) from this individual-by-group matrix.
adj=get_network(t(ibg), data_format=&quot;GBI&quot;, association_index=&quot;SRI&quot;)</code></pre>
<pre><code>## Generating  50  x  50  matrix</code></pre>
<pre class="r"><code>#create and plot network, with vertex size proportional to trait value
g=graph_from_adjacency_matrix(adj, &quot;undirected&quot;, weighted=T)
plot(g,vertex.size=trait/2, vertex.label=&quot;&quot;, edge.width=E(g)$weight*5)</code></pre>
<p><img src="09_permutations_files/figure-html/unnamed-chunk-2-1.png" width="384" /></p>
<p>We showed in this simulation that degree centrality is correlated to the trait:</p>
<pre class="r"><code>plot(trait, degree(g), pch=19)</code></pre>
<p><img src="09_permutations_files/figure-html/unnamed-chunk-3-1.png" width="384" /></p>
<pre class="r"><code>cor.test(trait, degree(g))</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  trait and degree(g)
## t = -8.0451, df = 48, p-value = 1.883e-10
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.8556276 -0.6075387
## sample estimates:
##        cor 
## -0.7577462</code></pre>
<p>Now, let’s test whether this pattern is statistically significant. That is, what is the probability that one would get this level of correlation between trait and degree by chance?</p>
<p>First, let’s store the correlation coefficient from our observed (simulated) network:</p>
<pre class="r"><code>obs.cor=cor(trait, degree(g))
obs.cor</code></pre>
<pre><code>## [1] -0.7577462</code></pre>
<p>Now, what we want to do is figure out what would be the correlation coefficient between trait and node degree if the trait value was randomized across individuals. This is what is called node label permutation.</p>
<p>What we need to do is randomize the trait value across individuals.</p>
<p>Here is one way:</p>
<pre class="r"><code>V(g)$trait=trait

V(g)$trait.random=sample(V(g)$trait, length(V(g)$trait), replace=F)

plot(V(g)$trait.random, degree(g))</code></pre>
<p><img src="09_permutations_files/figure-html/unnamed-chunk-5-1.png" width="384" /></p>
<pre class="r"><code>cor(V(g)$trait.random, degree(g))</code></pre>
<pre><code>## [1] 0.1578334</code></pre>
<p>Now, we will conduct this randomization a large number of times (say 1000 times) and measure the correlation coefficient each time. This will generate a null distribution of the correlation coefficient.</p>
<pre class="r"><code>times=100
randomized.networks=list()
for(i in 1:times){
  V(g)$trait.random=sample(V(g)$trait, length(V(g)$trait), replace=F)
  randomized.networks[[i]]=g
}

cor.random=sapply(randomized.networks, function(x) cor(V(x)$trait.random, degree(x)))

hist(cor.random, xlim=c(-1,1))
abline(v=obs.cor, lty=2, col=&quot;red&quot;)</code></pre>
<p><img src="09_permutations_files/figure-html/unnamed-chunk-6-1.png" width="384" /></p>
<pre class="r"><code>p.value=length(which(cor.random&lt;=obs.cor))/(times+1)
p.value</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
